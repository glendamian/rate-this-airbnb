{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2021</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Predicting Airbnb Scores Through User Submitted Reviews </h3> </center>\n",
    "<center><h4>Don Kim, Glen Damian Lim, Jason Fujii</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important links for this project:\n",
    "\n",
    "Github Repository Link: https://github.com/glendamian/rate_this_airbnb/tree/v1\n",
    "\n",
    "Google Colab Link: https://colab.research.google.com/drive/1GIptSdCmCNIryVXuVImEZsToMyRKCRN6?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "In this project, we will be looking at a dataset that we have cleaned ourselves about Airbnb listings. The Airbnb listings will be strictly in the Boston area for the sake of keeping the project at a reasonable scale. We will be predicting a binary value of whether a user should stay at a 'Best' listing or just a 'Decent' listing. This prediction will be made using the feature variables of text reviews and the ratings given by users out of a score of 5. The machine learning algorithms we will be using in this project are Logistic Regression Multinomial, Naive Bayes, and Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Problem Statement</h4>\n",
    "  \n",
    "  The topic of our project is Airbnb listings located throughout the Boston area. We are looking at listings in the Boston area for the sake of keeping this project in a doable scale. The problem we would like to tackle in this topic is to find a better metric for determining the best Airbnb listings a user should stay at. We as a group want to learn the average ratings users give these listings and if there is any relationship as to why these listings are more highly rated.\n",
    "\n",
    "<h4>Significance of the Problem</h4>\n",
    "\n",
    "  A simple 5 star rating is too vague of a factor to determine whether an Airbnb is the best place for a user to stay at. Furthermore, going through all written reviews isnâ€™t feasible. Therefore, we have taken it upon us to use machine learning algorithms to go through a large pool of diverse user reviews of Airbnb listings to efficiently give users a proper \"Best\" or \"Decent\" answer as to whether they should stay at a listing. We give these two strings as options because the average scores for the listings are very high by nature so we are trying to pinpoint which listings are the best to stay at.\n",
    "  \n",
    "  The insights we can gather from this project are what kind of keywords and reviews differentiate \"excellent\" Airbnb's from the \"decent\" ones, or if there is no difference in the keywords, at all. We can figure this out by analyzing our data after our machine learning algorithms are applied. We will be going through the text within the reviews given by users and use feature extraction using text to determine how accurate the 5 star ratings are. We can also possibly see if there is any specific location that has a more favored amount of listings that generate a positive score using our metric.\n",
    "\n",
    "<h4>Questions</h4>\n",
    "\n",
    "* Out of the three algorithms (Logistic Regression, Multinomial Naive Bayes, Decision Tree), which one yields the highest classification accuracy result? Which one out of the three algorithms can we use to predict whether a listing is a \"Best\" place to stay in or just a \"Decent\" place to stay in.\n",
    "\n",
    "* How many \"Best\" listings are there relative to how many \"Decent\" listings. Is there a wide difference?\n",
    "\n",
    "* Do the results change at all when run with a different instance? This can situation can possibly arise as new reviews are constantly being written every day for each listing on Airbnb. Or is it the case that these new entries do not skew the results of our algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "  \n",
    "  We obtained our data through a website called \"insideairbnb\" that provides datasets for Airbnb listings around the world.\n",
    "  You can find csv files containing information on the listings, reviews, calenders and neighbourhoods of a particular city.\n",
    "  Below attached is the link to the source:\n",
    "  \n",
    "  http://insideairbnb.com/get-the-data.html\n",
    "\n",
    "The listings.csv dataset describes for a given Airbnb certain variables such as the overall cleanliness rating, how many reviews per month and etc. for a total of about 70 variables by which each Airbnb is reviewed. The amount of samples included in the listings.csv is 3429, suggesting that for the most recent dataset for Boston there are 3429 Airbnbs reviewe. \n",
    "\n",
    "In the reviews.csv there are 126679 rows suggesting that there are 126679 total reviews they have accumulated for Boston. This also includes an ID for the Airbnb, such that we can match the two datasets on one Airbnb.\n",
    "\n",
    "We decided to pick 1200 random Airbnb's from the listings.csv, and select one comment from the 126679 for each such that in our final dataframe, there are 1200 individual Airbnbs with one comment matched by their unique ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Analysis\n",
    "\n",
    "The predictive model we are creating for this project will be a multiple regression model as we will be using supervised learning in this project. The outcome variable we will be going to predict is a binary value of whether a user should stay at an Airbnb listing or not. The feature variable that will be used to predict this outcome variable are the text reviews the user submits, the user rating score given out of 5, and the id of the listing.\n",
    "\n",
    "This is a supervised learning problem, which is sub-categorized to regression. We will be seeking to obtain a continuous output variable\n",
    "\n",
    "The machine learning algorithms we will be using along with a quick description of them are as follows:\n",
    "\n",
    "* Logistic Regression: A classification algorithm that is sed to predict the probability of a categorical dependent variable. The dependent variable is a binary variable that contains data coded as 1 (yes) or 0 (no). This right here is the main reason why we want to be using this regression model as it very closely resembles the dependent variable we are trying to output.\n",
    "  \n",
    "* Multinomial Naive Bayes: This is a probabilistic learning method that is mostly used in Natural Language Processing. This algorithm is based off the Bayes theorem and predicts the tag of a text - in our case the user reviews.\n",
    "  \n",
    "* Decision Tree Classifier: This algorithm hierarchically splits data down into subsets which are then split again into smaller subsets until all of thea features that have been split all belong to the same class. We want to try using this algorithm as it comes with the advantage of possibly improving our accuracy by setting the logic for the branches split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data Wrangling and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSVs and Convert to Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Load our two dataframes. This dataframe includes 3000+ Airbnb's with the 70 variables.\n",
    "listings = pd.read_csv(\"https://raw.githubusercontent.com/glendamian/rate_this_airbnb/main/listings.csv\")\n",
    "\n",
    "# This dataframe includes\n",
    "link = 'https://github.com/glendamian/rate_this_airbnb/blob/main/reviews.csv.zip?raw=true'\n",
    "request.urlretrieve(link, 'reviews.csv.zip')\n",
    "compressed_file = zipfile.ZipFile('reviews.csv.zip')\n",
    "csv_file = compressed_file.open('reviews.csv')\n",
    "reviews = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the count for each rating for the Review Scores Rating vs. Number of Reviews graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4.96</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4.97</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4.98</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4.99</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.00</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_scores_rating   id\n",
       "0                    0.00   12\n",
       "1                    1.00    9\n",
       "2                    1.50    1\n",
       "3                    2.00    5\n",
       "4                    2.33    3\n",
       "..                    ...  ...\n",
       "112                  4.96   39\n",
       "113                  4.97   23\n",
       "114                  4.98   23\n",
       "115                  4.99    8\n",
       "116                  5.00  482\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = listings.groupby(by=['review_scores_rating']).count()\n",
    "counts = counts.filter(['id', 'review_scores_rating'], axis=1).reset_index()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop nan values, duplicate IDs, unrelated columns for 1200 Airbnbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10813</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>10627514</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>19081593</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>48678923</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>33467259</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>28440873</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>8584276</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>43690782</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>48825405</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>39004265</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  review_scores_rating\n",
       "5        10813                  5.00\n",
       "468   10627514                  4.57\n",
       "835   19081593                  4.34\n",
       "2493  48678923                  4.81\n",
       "1483  33467259                  5.00\n",
       "...        ...                   ...\n",
       "1278  28440873                  4.79\n",
       "405    8584276                  4.38\n",
       "2006  43690782                  4.70\n",
       "2514  48825405                  4.80\n",
       "1724  39004265                  4.38\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop nan values from listing's score column\n",
    "listings.dropna(subset = [\"review_scores_rating\"], inplace=True)\n",
    "\n",
    "#Drop duplicates\n",
    "listings.drop_duplicates([\"id\"])\n",
    "\n",
    "# Randomly sample 1200 Airbnb's of the 3000+\n",
    "listings = listings.sample(n=1200)\n",
    "\n",
    "# Filter out the id to merge the two dataframes and score so that we can determine if the Airbnb is recommended or not.\n",
    "listings = listings.filter(['id', 'review_scores_rating'], axis=1)\n",
    "\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data such that scores below the median review rating are considered \"decent\" instead of \"best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8 is this iteration's median score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>10627514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>19081593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>48678923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>33467259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>28440873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>8584276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>43690782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>48825405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>39004265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  review_scores_rating\n",
       "5        10813                     1\n",
       "468   10627514                     0\n",
       "835   19081593                     0\n",
       "2493  48678923                     1\n",
       "1483  33467259                     1\n",
       "...        ...                   ...\n",
       "1278  28440873                     0\n",
       "405    8584276                     0\n",
       "2006  43690782                     0\n",
       "2514  48825405                     0\n",
       "1724  39004265                     0\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find mean score for review_scores_rating to determine cutoff between decent and best Airbnb's.\n",
    "median_score = listings['review_scores_rating'].median()\n",
    "\n",
    "print(str(median_score) + \" is this iteration's median score\")\n",
    "\n",
    "def best_airbnb(score):\n",
    "    if score <= median_score:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "listings[\"review_scores_rating\"] = listings[\"review_scores_rating\"].map(best_airbnb)\n",
    "\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename ID column to 'listing_id', same as in reviews dataframe, and set as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37152036</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51582251</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040760</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45652898</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758462</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930647</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089865</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315428</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28756042</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52234930</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change name of id column for merge operation.\n",
    "listings = listings.rename(columns={'id': 'listing_id'})\n",
    "\n",
    "listings.set_index('listing_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate reviews for reviews dataframe such that only one review per Airbnb. Filter out id and comment columns. Set listing_id to index for join operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>The apartment was as advertised and Frank was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>Terry's Hotel Alterntv in Boston was a perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>Terry's apartment is beautifully decorated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>Great accommodations for the price and nearby ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10730</th>\n",
       "      <td>I went to Boston with my wife and my 7-month o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52613030</th>\n",
       "      <td>I really enjoyed my stay here! Meredith provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52614016</th>\n",
       "      <td>Such a warm and welcoming place.  Thanks guys!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52615785</th>\n",
       "      <td>Great location &lt;br/&gt;Steven was a great host co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52615817</th>\n",
       "      <td>This place is very clean and comfortable. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52653198</th>\n",
       "      <td>Had a great stay! Very clean home in a quite, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2334 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews = reviews.drop_duplicates([\"listing_id\"])\n",
    "\n",
    "reviews = reviews.filter(['listing_id', 'comments'], axis=1)\n",
    "\n",
    "reviews.set_index([\"listing_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the reviews dataframe and listings dataframe into one merged_data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37152036</td>\n",
       "      <td>0</td>\n",
       "      <td>Great apartment. All amenities youâ€™d want, ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51582251</td>\n",
       "      <td>0</td>\n",
       "      <td>Overall great experience. Exactly what i expec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16040760</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Airbnb experiences ever! Self check-in wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45652898</td>\n",
       "      <td>1</td>\n",
       "      <td>Our stay at Cindyâ€™s place was phenomenal. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6758462</td>\n",
       "      <td>0</td>\n",
       "      <td>The place has an excellent location. The bed i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>31930647</td>\n",
       "      <td>1</td>\n",
       "      <td>Tremendous experience in this apartment.  Abso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>6089865</td>\n",
       "      <td>0</td>\n",
       "      <td>Couldn't have been better, I used to live in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>4315428</td>\n",
       "      <td>0</td>\n",
       "      <td>The home is very nice. The room is large and v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>28756042</td>\n",
       "      <td>0</td>\n",
       "      <td>I was pretty impressed by the amenities offere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>52234930</td>\n",
       "      <td>0</td>\n",
       "      <td>Offering this place up for travel nurses is en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_data = pd.merge(listings, reviews, on=\"listing_id\", how=\"inner\")\n",
    "\n",
    "# Then inner merge\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split number of best and decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df_equally_by_group(df, column, n):\n",
    "    data1 = df[df[column] == 1].sample(n = n)\n",
    "    data2 = df[df[column] == 0].sample(n = n)\n",
    "\n",
    "    results = data1.append(data2)\n",
    "    return results.sort_values(by=[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Stylecloud Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf9d38962fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstylecloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Best reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_scores_rating\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Decent reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_scores_rating\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_data' is not defined"
     ]
    }
   ],
   "source": [
    "import stylecloud\n",
    "# Best reviews\n",
    "best = final_data[final_data[\"review_scores_rating\"] == 1][\"comments\"].tolist()\n",
    "# Decent reviews\n",
    "decent = final_data[final_data[\"review_scores_rating\"] == 0][\"comments\"].tolist()\n",
    "valueBest = ''.join(best)\n",
    "valueDecent = ''.join(decent)\n",
    "# Best word cloud\n",
    "stylecloud.gen_stylecloud(text= valueBest, output_name=\"vis_best_listings.png\")\n",
    "# Decent word cloud\n",
    "stylecloud.gen_stylecloud(text= valueDecent, output_name=\"vis_decent_listings.png\")\n",
    "\n",
    "#It is shown from the output of our wordclouds are not that different from one another.\n",
    "#This might be the result of the dataset that we obtained, which has an extremely high median value, indicating that \n",
    "#there are a significantly higher number of values of good reviews compared to the bad ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the word cloud of the best listings:\n",
    "<img src=\"https://i.ibb.co/b6NX71r/vis-best-listings.png\" alt=\"vis-false-headlines\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the word cloud of the decent listings:\n",
    "<img src=\"https://i.ibb.co/sj2JQ80/vis-decent-listings.png\" alt=\"vis-false-headlines\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Scatter Plot Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Text(0, 0.5, 'Number of Reviews')"
      ]
     },
     "metadata": {
      "image/png": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#Get the number of times a review score rating ocurred.\n",
    "counts = listings.groupby(by=['review_scores_rating']).count()\n",
    "counts = counts.filter(['id', 'review_scores_rating'], axis=1).reset_index()\n",
    "\n",
    "# create and display the scatter plot\n",
    "graph = sns.scatterplot(x=\"review_scores_rating\", y=\"id\", data = counts)\n",
    "\n",
    "#specify the title\n",
    "title = \"Review Scores Rating vs Number of Reviews\"\n",
    "\n",
    "#set the title of the plot\n",
    "graph.set_title(title, size = 16)\n",
    "\n",
    "#add labels to the axes  \n",
    "graph.set_xlabel(\"Rating\", size = 16)\n",
    "graph.set_ylabel(\"Number of Reviews\", size = 16)\n",
    "\n",
    "#The scatter-plot has shown that there is a significant amount of higher rating reviews compared to the lower ones\n",
    "# in our original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter-plot visualization:\n",
    "<img src=\"https://i.ibb.co/R0d9507/Screen-Shot-2021-12-10-at-6-55-02-PM.png\" alt=\"vis-false-headlines\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training, Validation, and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorizer/bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set features and target arrays to split data\n",
    "features = merged_data[\"comments\"]\n",
    "target = merged_data[\"review_scores_rating\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "# Set validation data to 10% of training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .10)\n",
    "\n",
    "# create the vocabulary based on the training data, using stop words (would've done bigrams, but RFE took over 10 minutes and\n",
    "# still didn't finish)\n",
    "vect = CountVectorizer(stop_words = \"english\").fit(X_train.values.astype('U'))\n",
    "vect.fit(X_train.values.astype('U'))\n",
    "\n",
    "#encode and transform data sets for words based on the vocabulary, also X_test for last testing data\n",
    "X_train_vectorized = vect.transform(X_train.values.astype('U'))\n",
    "X_validation_vectorized = vect.transform(X_val.values.astype('U'))\n",
    "X_test_vectorized = vect.transform(X_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE for Feature Selection (might take a few minutes to load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#select 100 words out of the original 4308\n",
    "select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 100)\n",
    "\n",
    "#fit RFE to the training data\n",
    "select.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#only the selected features are retained for the vectorized sets.\n",
    "X_train_selected = select.transform(X_train_vectorized)\n",
    "X_val_selected = select.transform(X_validation_vectorized)\n",
    "X_test_selected = select.transform(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply 3 Machine Learning Algorithms (DecisionTreeClassifier, LogisticRegression, MultinomialNB)\n",
    "#### Train algorithms with the Training Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb Best estimator:  MultinomialNB(alpha=0.1)\n",
      "mnb Best parameters:  {'alpha': 0.1}\n",
      "mnb Best cross-validation score:  0.6111111111111112\n",
      "mnb Validation set score:  0.6111111111111112\n",
      "lr Best estimator:  LogisticRegression()\n",
      "lr Best parameters:  {'max_iter': 100}\n",
      "lr Best cross-validation score:  0.6049382716049383\n",
      "lr Validation set score:  0.5222222222222223\n",
      "tree Best estimator:  DecisionTreeClassifier(max_depth=100)\n",
      "tree Best parameters:  {'max_depth': 100}\n",
      "tree Best cross-validation score:  0.5703703703703704\n",
      "tree Validation set score:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# List of desired algorithms which we wish to test.\n",
    "est = {'mnb': MultinomialNB(), 'lr':LogisticRegression(), 'tree':DecisionTreeClassifier()}\n",
    "\n",
    "# For each algorithm, specify 3 different parameters by which we can find the optimal parameter.\n",
    "params = {'mnb':{'alpha':[1, 0.1, 10]}, 'lr':{\"max_iter\":[1, 10, 100]},'tree':{\"max_depth\":[1, 10, 100]}}\n",
    "\n",
    "# For each algorithm, find the best esimator, parameter, cross-validation score, and the Validation set score.\n",
    "for key, value in est.items():\n",
    "    for param, y in params.items():\n",
    "        if key == param:\n",
    "            grid_search = GridSearchCV(value, y, cv=5)\n",
    "            grid_search.fit(X=X_train_selected, y=y_train)\n",
    "            print(key + \" Best estimator: \", grid_search.best_estimator_)\n",
    "            print(key + \" Best parameters: \", grid_search.best_params_)\n",
    "            print(key + \" Best cross-validation score: \", grid_search.best_score_)\n",
    "            print(key + \" Validation set score: \", grid_search.score(X_val_selected, y_val))\n",
    "\n",
    "\n",
    "# This iteration shows that MultinomialNB with an alpha=0.1 provides the best cross-validation score and Validation \n",
    "# set scores, suggesting that is the best model for us to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing All Features Model to Previous Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb Best estimator:  MultinomialNB(alpha=1)\n",
      "mnb Best parameters:  {'alpha': 1}\n",
      "mnb Best cross-validation score:  0.5765432098765432\n",
      "mnb Validation set score:  0.6\n",
      "lr Best estimator:  LogisticRegression(max_iter=1)\n",
      "lr Best parameters:  {'max_iter': 1}\n",
      "lr Best cross-validation score:  0.562962962962963\n",
      "lr Validation set score:  0.6111111111111112\n",
      "tree Best estimator:  DecisionTreeClassifier(max_depth=100)\n",
      "tree Best parameters:  {'max_depth': 100}\n",
      "tree Best cross-validation score:  0.5345679012345679\n",
      "tree Validation set score:  0.4777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "est = {'mnb': MultinomialNB(), 'lr':LogisticRegression(), 'tree':DecisionTreeClassifier()}\n",
    "\n",
    "params = {'mnb':{'alpha':[1, 0.1, 10]}, 'lr':{\"max_iter\":[1, 10, 100]},'tree':{\"max_depth\":[1, 10, 100]}}\n",
    "\n",
    "for key, value in est.items():\n",
    "    for param, y in params.items():\n",
    "        if key == param:\n",
    "            grid_search = GridSearchCV(value, y, cv=5)\n",
    "            grid_search.fit(X=X_train_vectorized, y=y_train)\n",
    "            print(key + \" Best estimator: \", grid_search.best_estimator_)\n",
    "            print(key + \" Best parameters: \", grid_search.best_params_)\n",
    "            print(key + \" Best cross-validation score: \", grid_search.best_score_)\n",
    "            print(key + \" Validation set score: \", grid_search.score(X_validation_vectorized, y_val))\n",
    "\n",
    "\n",
    "# Results show that with all features, the accuracy has decreased compared to when we only selected 100 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55        47\n",
      "           1       0.54      0.63      0.58        43\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.57      0.57      0.57        90\n",
      "weighted avg       0.57      0.57      0.57        90\n",
      "\n",
      "Prediction accuracy on the training data: 66.54\n",
      "Prediction accuracy on the validation data: 56.67\n"
     ]
    }
   ],
   "source": [
    "# Comparing MNB with alpha of 10\n",
    "from sklearn.metrics import classification_report\n",
    "model = MultinomialNB(alpha=10)\n",
    "\n",
    "# Fit the model based on the training data.\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "predicted = model.predict(X=X_val_selected)\n",
    "expected = y_val\n",
    "\n",
    "# Evalulate the performance of our algorithms based on multiple metrics.\n",
    "class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "print (class_report)\n",
    "\n",
    "# Find prediction accuracy for the given algorithm and parameter.\n",
    "print(\"Prediction accuracy on the training data:\", format(model.score(X_train_selected, y_train)*100, \".2f\"))\n",
    "print(\"Prediction accuracy on the validation data:\", format(model.score(X_val_selected, y_val)*100, \".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.54        47\n",
      "           1       0.50      0.51      0.51        43\n",
      "\n",
      "    accuracy                           0.52        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.52      0.52      0.52        90\n",
      "\n",
      "Prediction accuracy on the training data: 67.65\n",
      "Prediction accuracy on the validation data: 52.22\n"
     ]
    }
   ],
   "source": [
    "# Comparing logistic regression w/ max-iter of 10.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression(max_iter=10)\n",
    "\n",
    "# Fit the model based on the training data.\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "predicted = model.predict(X=X_val_selected)\n",
    "expected = y_val\n",
    "\n",
    "# Evalulate the performance of our algorithms based on multiple metrics.\n",
    "class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "print (class_report)\n",
    "\n",
    "# Find prediction accuracy for the given algorithm and parameter.\n",
    "print(\"Prediction accuracy on the training data:\", format(model.score(X_train_selected, y_train)*100, \".2f\"))\n",
    "print(\"Prediction accuracy on the validation data:\", format(model.score(X_val_selected, y_val)*100, \".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60        47\n",
      "           1       0.58      0.67      0.62        43\n",
      "\n",
      "    accuracy                           0.61        90\n",
      "   macro avg       0.61      0.61      0.61        90\n",
      "weighted avg       0.62      0.61      0.61        90\n",
      "\n",
      "Prediction accuracy on the training data: 69.14\n",
      "Prediction accuracy on the validation data: 61.11\n",
      "The cross-validation score and the prediction accuracy on the training data are not 100 but not super loweither suggesting neither over or underfitting significantly.\n"
     ]
    }
   ],
   "source": [
    "# checking that suboptimal parameters lowers score.\n",
    "from sklearn.metrics import classification_report\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "predicted = model.predict(X=X_val_selected)\n",
    "expected = y_val\n",
    "class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "print (class_report)\n",
    "\n",
    "print(\"Prediction accuracy on the training data:\", format(model.score(X_train_selected, y_train)*100, \".2f\"))\n",
    "print(\"Prediction accuracy on the validation data:\", format(model.score(X_val_selected, y_val)*100, \".2f\"))\n",
    "\n",
    "# The prediction accuracy score on the training data is the highest here, compared to the previous cell\n",
    "# where the alpha was 10, and when we used LogisticRegression instead of MNB,\n",
    "# suggesting that the MNB with an alpha of 0.1 is optimal, as the gridsearch suggested.\n",
    "\n",
    "print(\"The cross-validation score and the prediction accuracy on the training data are not 100 but not super low\"\n",
    "      + \"either suggesting neither over or underfitting significantly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.49      0.52       148\n",
      "           1       0.55      0.61      0.58       152\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.55      0.55      0.55       300\n",
      "weighted avg       0.55      0.55      0.55       300\n",
      "\n",
      "Prediction accuracy on the training data: 69.14\n",
      "Prediction accuracy on the test data: 55.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "predicted = model.predict(X=X_test_selected)\n",
    "expected = y_test\n",
    "class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "print (class_report)\n",
    "\n",
    "print(\"Prediction accuracy on the training data:\", format(model.score(X_train_selected, y_train)*100, \".2f\"))\n",
    "print(\"Prediction accuracy on the test data:\", format(model.score(X_test_selected, y_test)*100, \".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "\n",
    "We compared the results of Logistic Regression, Multinomial Naive Bayes and Decision Tree Classifier to determine\n",
    "which algorithm(s) will be the best to tackle this problem.\n",
    "    \n",
    "   We used GridSearch for hyperparameter tuning to determine the best parameters and to check whether our model is overfitted or not. Best on the result of the GridSearch, while we are trying to determine which is the best estimator for our model. The results of our algorithms change with each instance that we run it, but we found that on average, the algorithm that has the highest cross validation score and validation set score is the Multinomial Naive Bayes algorithm. The best parameter to use for this algorithm is 'alpha=0.1'. The cross-validation score and the prediction accuracy on the training data are not 100 but not super low which suggest neither over or underfitting significantly. \n",
    "   \n",
    "   Based off of these results, the algorithm that we used for our predictive model is Multinomial Naive Bayes. Based on our findings, it is safe to say that we are able to use the features in our dataset to predict the outcome variable we identified using the algorithms we applied. There is one issue that may arise for ethical implications on this project. The issue is that we use the median of the average ratings in our data to make it easier to use for us because the majority of the reviews are all heavily skewed toward a perfect 5 star rating. Other dataset bias can come from how there aren't many reviews for some listings while other listings have a great amount of reviews. For the sake of our project we manipulated our dataset to only have one review for each unique listing so this may cause a fair amount of bias in our dataset. This is because one review for a specific listing can be an outlier in the listing's general reception amongst other reviews by users.\n",
    "\n",
    "For any future work we can possibly use a less biased dataset as we did for the sake of this project to possibly glean any further insights. We can also apply our work on this project to other regions and see what kind of data is yielded there. This may show us that different algorithms are more favorable to use compared to the ones that we declared to be the best in our project. Also, other algorithms besides the three that we used can be applied to see any different results.\n",
    "\n",
    "## Answers to our questions from Part 1\n",
    "\n",
    "   Upon our implementation of our algorithms we can answer the questions we have asked ourselves in Part 1 of this project:\n",
    "\n",
    "   * Out of the three algorithms (Logistic Regression, Multinomial Naive Bayes, Decision Tree), which one yields the highest classification accuracy result? Which one out of the three algorithms can we use to predict whether a listing is a \"Best\" place to stay in or just a \"Decent\" place to stay in?\n",
    "\n",
    "      Multinomial Naive Bayes was the machine learning algorithm that yielded the highest classification accuracy result. Multinomial Naive Bayes is also the algorithm that we can use to predict our binary target variable.\n",
    "\n",
    "* How many \"Best\" listings are there relative to how many \"Decent\" listings. Is there a wide difference?\n",
    "\n",
    "   The amount of \"Best\" listings is actually not too far from the amount of \"Decent\" listings because of the high saturation of very highly rated reviews in the dataset. If we wanted to pinpoint it further we would have to be stricter with what exact score we determine to be a \"Best\" listing.\n",
    "\n",
    "* Do the results change at all when run with a different instance? This can situation can possibly arise as new reviews are constantly being written every day for each listing on Airbnb. Or is it the case that these new entries do not skew the results of our algorithms?\n",
    "\n",
    "   The results do change slightly when run with different instances but it does not create a very large disparity amongst one another. Overall, the majority of the instances show that Multinomial Naive Bayes is still the best machine learning algorithm to use for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
